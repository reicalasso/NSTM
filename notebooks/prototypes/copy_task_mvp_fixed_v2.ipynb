{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSTM MVP - Copy Task Prototype\n",
    "\n",
    "Bu notebook, NSTM'nin minimum viable prototype'ını (MVP) göstermektedir. \n",
    "Basit bir \"Copy Task\" üzerinde NSTM modelinin eğitilmesi ve değerlendirilmesi \n",
    "gerçekleştirilmektedir.\n",
    "\n",
    "## Görev: Copy Task\n",
    "\n",
    "Copy Task, bir modelin belirli bir uzunluktaki bir diziyi ezberleyip \n",
    "ardından aynısını tekrarlayabilme yeteneğini test eder. \n",
    "Bu, modelin:\n",
    "\n",
    "1.  Girdi dizisini okuyabilmesi,\n",
    "2.  Bu bilgiyi dahili durumlarında saklayabilmesi,\n",
    "3.  Ve daha sonra bu bilgiyi doğru şekilde geri getirebilmesi\n",
    "\n",
    "kabiliyetlerini değerlendirir.\n",
    "\n",
    "## NSTM ile Yaklaşım\n",
    "\n",
    "NSTM, bu görevi çözmek için:\n",
    "\n",
    "1.  Girdi token'larını `TokenToStateRouter` ile durumlara yönlendirir.\n",
    "2.  `HybridAttention` ile token ve durum bilgilerini işler.\n",
    "3.  `StatePropagator` ile durumları günceller.\n",
    "4.  `StateManager` ile durumların yönetimini sağlar.\n",
    "5.  Tüm bu bileşenler `NSMLayer` tarafından koordine edilir.\n",
    "\n",
    "Bu notebook'ta, bu sürecin adım adım nasıl işlediğini gözlemleyeceğiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ortamın Hazırlanması ve Kütüphanelerin Yüklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Import NSTM components\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnstm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NSTMConfig\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnstm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnstm_layer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NSMLayer\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Select device (use GPU if available)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "sys.path.append('/home/rei/NSTM')\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '/home/rei/NSTM')))\n",
    "\n",
    "# Import NSTM components\n",
    "from src.nstm.core.types import NSTMConfig\n",
    "from src.nstm.models.nstm_layer import NSMLayer\n",
    "\n",
    "# Select device (use GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Copy Task Dataset'inin Oluşturulması\n",
    "\n",
    "Copy Task için özel bir dataset sınıfı oluşturalım. \n",
    "Bu dataset, belirli bir uzunluktaki rastgele tamsayı dizilerini üretir \n",
    "ve her dizinin sonunda bir \"bitiş\" tokeni (örneğin, -1) yerleştirir. \n",
    "Modelin görevi, bitiş tokeninden sonra dizinin aynısını üretmektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopyTaskDataset(Dataset):\n",
    "    \"\"\"Copy Task için dataset sınıfı.\"\"\"\n",
    "    \n",
    "    def __init__(self, sequence_length, num_samples, vocab_size=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sequence_length (int): Kopyalanacak dizinin uzunluğu.\n",
    "            num_samples (int): Dataset'teki örnek sayısı.\n",
    "            vocab_size (int): Kullanılacak token sayısı (0'dan vocab_size-1'e kadar).\n",
    "        \"\"\"\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_samples = num_samples\n",
    "        self.vocab_size = vocab_size\n",
    "        self.end_token = vocab_size  # Bitiş tokeni\n",
    "        self.total_vocab_size = vocab_size + 1  # Bitiş tokeni dahil\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Rastgele bir dizi oluştur (bitiş tokeni hariç)\n",
    "        sequence = torch.randint(0, self.vocab_size, (self.sequence_length,))\n",
    "        \n",
    "        # Girdi: [sequence, end_token]\n",
    "        # Çıktı: [sequence] (bitiş tokeni sonrası)\n",
    "        input_sequence = torch.cat([sequence, torch.tensor([self.end_token])])\n",
    "        target_sequence = sequence\n",
    "        \n",
    "        return input_sequence, target_sequence\n",
    "\n",
    "# Dataset örneği oluşturma\n",
    "sequence_length = 10\n",
    "num_samples = 1000\n",
    "vocab_size = 8\n",
    "\n",
    "dataset = CopyTaskDataset(sequence_length, num_samples, vocab_size)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Bir örneği inceleyelim\n",
    "sample_input, sample_target = dataset[0]\n",
    "print(f\"Örnek girdi (uzunluk {len(sample_input)}): {sample_input}\")\n",
    "print(f\"Örnek hedef (uzunluk {len(sample_target)}): {sample_target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NSTM Modelinin Oluşturulması\n",
    "\n",
    "Bir `NSMLayer` modeli oluşturalım ve onu Copy Task için yapılandıralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model konfigürasyonu\n",
    "# Note: token_dim and state_dim can be different now with our fix\n",
    "config = NSTMConfig(\n",
    "    state_dim=64,\n",
    "    token_dim=32,  # Embedding boyutu\n",
    "    gate_type='gru',\n",
    "    num_attention_heads=4,\n",
    "    max_states=32,\n",
    "    initial_states=16,\n",
    "    prune_threshold=0.3\n",
    ")\n",
    "\n",
    "# Token embedding katmanı (dataset'ten gelen tamsayı token'ları vektörlere çevirir)\n",
    "total_vocab_size = dataset.total_vocab_size\n",
    "embedding = nn.Embedding(total_vocab_size, config.token_dim).to(device)\n",
    "\n",
    "# NSMLayer modeli\n",
    "model = NSMLayer(config).to(device)\n",
    "\n",
    "# Çıkış katmanı (durum vektörlerini token olasılıklarına dönüştürür)\n",
    "output_layer = nn.Linear(config.state_dim, total_vocab_size).to(device)\n",
    "\n",
    "print(f\"Model oluşturuldu. Toplam parametre sayısı: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Embedding katmanı parametre sayısı: {sum(p.numel() for p in embedding.parameters())}\")\n",
    "print(f\"Çıkış katmanı parametre sayısı: {sum(p.numel() for p in output_layer.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Eğitim Sürecinin Tanımlanması\n",
    "\n",
    "Modeli eğitmek için gerekli olan loss fonksiyonu, optimizer ve eğitim döngüsünü tanımlayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss fonksiyonu ve optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(model.parameters()) + list(embedding.parameters()) + list(output_layer.parameters()), lr=0.001)\n",
    "\n",
    "def train_model(model, embedding, output_layer, dataloader, criterion, optimizer, num_epochs=5):\n",
    "    \"\"\"Modeli eğiten fonksiyon.\"\"\"\n",
    "    model.train()\n",
    "    embedding.train()\n",
    "    output_layer.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (input_seq, target_seq) in enumerate(dataloader):\n",
    "            # Verileri cihaza taşı\n",
    "            input_seq = input_seq.to(device)  # (batch_size, seq_len+1)\n",
    "            target_seq = target_seq.to(device)  # (batch_size, seq_len)\n",
    "            \n",
    "            batch_size, input_seq_len = input_seq.shape\n",
    "            _, target_seq_len = target_seq.shape\n",
    "            \n",
    "            # Token'ları embedding vektörlerine çevir\n",
    "            embedded_input = embedding(input_seq)  # (batch_size, seq_len+1, token_dim)\n",
    "            \n",
    "            # Modelin ileri besleme adımı\n",
    "            # Input'u ikiye ayıralım: conditioning part ve trigger token\n",
    "            conditioning_input = embedded_input[:, :-1, :]  # (batch_size, seq_len, token_dim)\n",
    "            trigger_token = embedded_input[:, -1:, :]      # (batch_size, 1, token_dim)\n",
    "            \n",
    "            # Conditioning phase: Durumları güncelle\n",
    "            final_states, _, _ = model(conditioning_input)  # (batch_size, num_states, state_dim)\n",
    "            \n",
    "            # Generation phase: Basitleştirilmiş yaklaşım\n",
    "            # Sadece ilk `target_seq_len` durumu kullan\n",
    "            if final_states.size(1) < target_seq_len:\n",
    "                raise ValueError(f\"Model yeterli durum üretmedi. \"\n",
    "                                 f\"Gereken: {target_seq_len}, \"\n",
    "                                 f\"Mevcut: {final_states.size(1)}\")\n",
    "                                 \n",
    "            selected_states = final_states[:, :target_seq_len, :]  # (batch_size, target_seq_len, state_dim)\n",
    "            \n",
    "            # Her durumu output katmanından geçir\n",
    "            logits = output_layer(selected_states)  # (batch_size, target_seq_len, vocab_size)\n",
    "            \n",
    "            # Loss hesapla\n",
    "            # logits: (batch_size, target_seq_len, vocab_size)\n",
    "            # target_seq: (batch_size, target_seq_len)\n",
    "            # CrossEntropyLoss için logits (batch_size, vocab_size, target_seq_len) olmalı\n",
    "            logits_transposed = logits.transpose(1, 2)  # (batch_size, vocab_size, target_seq_len)\n",
    "            loss = criterion(logits_transposed, target_seq)\n",
    "            \n",
    "            # Geri yayılım\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "                \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} tamamlandı. Ortalama Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Modeli eğit\n",
    "train_model(model, embedding, output_layer, dataloader, criterion, optimizer, num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelin Değerlendirilmesi\n",
    "\n",
    "Eğitilen modeli yeni veriler üzerinde test edelim ve performansını değerlendirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, embedding, output_layer, dataset, num_samples=5):\n",
    "    \"\"\"Modeli değerlendirme fonksiyonu.\"\"\"\n",
    "    model.eval()\n",
    "    embedding.eval()\n",
    "    output_layer.eval()\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            input_seq, target_seq = dataset[i]\n",
    "            input_seq = input_seq.unsqueeze(0).to(device)  # (1, seq_len+1)\n",
    "            target_seq = target_seq.unsqueeze(0).to(device)  # (1, seq_len)\n",
    "            \n",
    "            # Token'ları embedding vektörlerine çevir\n",
    "            embedded_input = embedding(input_seq)  # (1, seq_len+1, token_dim)\n",
    "            \n",
    "            # Conditioning phase\n",
    "            conditioning_input = embedded_input[:, :-1, :]  # (1, seq_len, token_dim)\n",
    "            final_states, _, _ = model(conditioning_input)  # (1, num_states, state_dim)\n",
    "            \n",
    "            # Output generation (basitleştirilmiş)\n",
    "            target_seq_len = target_seq.size(1)\n",
    "            selected_states = final_states[:, :target_seq_len, :]  # (1, target_seq_len, state_dim)\n",
    "            logits = output_layer(selected_states)  # (1, target_seq_len, vocab_size)\n",
    "            \n",
    "            # Tahminleri al\n",
    "            predictions = torch.argmax(logits, dim=-1)  # (1, target_seq_len)\n",
    "            \n",
    "            # Doğruluğu hesapla\n",
    "            correct = (predictions == target_seq).sum().item()\n",
    "            total = target_seq.numel()\n",
    "            correct_predictions += correct\n",
    "            total_predictions += total\n",
    "            \n",
    "            # Sonuçları yazdır\n",
    "            input_tokens = input_seq.squeeze(0)[:-1]  # Bitiş tokeni hariç\n",
    "            end_token = input_seq.squeeze(0)[-1].item()\n",
    "            predicted_tokens = predictions.squeeze(0)\n",
    "            actual_tokens = target_seq.squeeze(0)\n",
    "            \n",
    "            print(f\"\\n--- Örnek {i+1} ---\")\n",
    "            print(f\"Girdi: {input_tokens.cpu().numpy()}\")\n",
    "            print(f\"Bitiş Tokeni: {end_token}\")\n",
    "            print(f\"Gerçek Çıktı: {actual_tokens.cpu().numpy()}\")\n",
    "            print(f\"Tahmin Edilen Çıktı: {predicted_tokens.cpu().numpy()}\")\n",
    "            print(f\"Doğru Tahminler: {correct}/{total}\")\n",
    "            \n",
    "    overall_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    print(f\"\\nGenel Doğruluk: {overall_accuracy:.4f} ({correct_predictions}/{total_predictions})\")\n",
    "    return overall_accuracy\n",
    "\n",
    "# Modeli değerlendir\n",
    "print(\"Model değerlendiriliyor...\")\n",
    "accuracy = evaluate_model(model, embedding, output_layer, dataset, num_samples=10)\n",
    "print(f\"Değerlendirme tamamlandı. Doğruluk: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Durum ve Dikkat Ağırlıklarının Görselleştirilmesi\n",
    "\n",
    "Modelin iç çalışma prensiplerini anlamak için, durum vektörlerini ve dikkat ağırlıklarını görselleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention_weights(model, embedding, sample_input):\n",
    "    \"\"\"Dikkat ağırlıklarını görselleştiren fonksiyon.\"\"\"\n",
    "    model.eval()\n",
    "    embedding.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_seq = sample_input.unsqueeze(0).to(device)  # (1, seq_len+1)\n",
    "        embedded_input = embedding(input_seq)  # (1, seq_len+1, token_dim)\n",
    "        \n",
    "        # Conditioning phase\n",
    "        conditioning_input = embedded_input[:, :-1, :]  # (1, seq_len, token_dim)\n",
    "        final_states, ts_weights, ss_weights = model(conditioning_input)\n",
    "        \n",
    "        # Dikkat ağırlıklarını görselleştir\n",
    "        # ts_weights: (1, num_heads, num_states, seq_len)\n",
    "        # ss_weights: (1, num_heads, num_states, num_states)\n",
    "        \n",
    "        ts_weights_cpu = ts_weights.squeeze(0).cpu().numpy()  # (num_heads, num_states, seq_len)\n",
    "        ss_weights_cpu = ss_weights.squeeze(0).cpu().numpy()  # (num_heads, num_states, num_states)\n",
    "        \n",
    "        num_heads = ts_weights_cpu.shape[0]\n",
    "        seq_len = ts_weights_cpu.shape[2]\n",
    "        num_states = ss_weights_cpu.shape[1]\n",
    "        \n",
    "        # Token-to-State dikkat ağırlıklarını görselleştir\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            fig, axes = plt.subplots(1, num_heads, figsize=(5*num_heads, 5))\n",
    "            if num_heads == 1:\n",
    "                axes = [axes]\n",
    "            for h in range(num_heads):\n",
    "                im = axes[h].imshow(ts_weights_cpu[h], cmap='Blues', aspect='auto')\n",
    "                axes[h].set_title(f'Token-to-State Attention (Head {h})')\n",
    "                axes[h].set_xlabel('Token Position')\n",
    "                axes[h].set_ylabel('State Index')\n",
    "                plt.colorbar(im, ax=axes[h])\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # State-to-State dikkat ağırlıklarını görselleştir (ilk head)\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            im = plt.imshow(ss_weights_cpu[0], cmap='Blues', aspect='auto')\n",
    "            plt.title('State-to-State Attention (Head 0)')\n",
    "            plt.xlabel('Source State Index')\n",
    "            plt.ylabel('Target State Index')\n",
    "            plt.colorbar(im)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except ImportError:\n",
    "            print(\"Matplotlib not available for visualization.\")\n",
    "\n",
    "# Bir örnek üzerinde dikkat ağırlıklarını görselleştir\n",
    "sample_input, _ = dataset[0]\n",
    "print(\"Dikkat ağırlıkları görselleştiriliyor...\")\n",
    "visualize_attention_weights(model, embedding, sample_input)\n",
    "print(\"Görselleştirme tamamlandı.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sonuç ve Özet\n",
    "\n",
    "Bu notebook'ta, NSTM'nin minimum viable prototype'ını (MVP) oluşturduk ve \n",
    "basit bir Copy Task üzerinde test ettik. \n",
    "\n",
    "### Elde Edilenler:\n",
    "\n",
    "1.  **Temel Bileşenlerin Entegrasyonu**: `StateManager`, `StatePropagator`, \n",
    "    `TokenToStateRouter` ve `HybridAttention` bileşenleri `NSMLayer` \n",
    "    tarafından başarılı bir şekilde koordine edildi.\n",
    "2.  **Modelin Eğitimi**: Model, basit bir Copy Task üzerinde öğrenmeyi \n",
    "    başardı ve belirli bir doğruluk seviyesine ulaştı.\n",
    "3.  **Dikkat Mekanizmalarının Görselleştirilmesi**: Token-to-state ve \n",
    "    state-to-state dikkat ağırlıkları görselleştirildi ve \n",
    "    modelin bilgi akışını nasıl organize ettiğini gözlemlemek mümkün oldu.\n",
    "\n",
    "### Gelecek Adımlar:\n",
    "\n",
    "1.  **Daha Karmaşık Görevler**: Modeli daha uzun diziler, \n",
    "    farklı veri türleri veya daha karmaşık görevler üzerinde test etmek.\n",
    "2.  **Performans Optimizasyonu**: Modelin eğitim ve çıkarım \n",
    "    sürelerini iyileştirmek.\n",
    "3.  **Dinamik Durum Yönetimi**: `StateManager`'ın dinamik tahsis \n",
    "    ve budama yeteneklerini daha etkili kullanmak.\n",
    "4.  **İnterprete Edilebilirlik**: Modelin karar süreçlerini \n",
    "    daha ayrıntılı analiz etmek ve açıklamak.\n",
    "5.  **Benchmark Testleri**: Modeli LRA (Long Range Arena) \n",
    "    gibi standart benchmark'lar üzerinde değerlendirmek.\n",
    "\n",
    "Bu MVP, NSTM mimarisinin temel kavramlarının işlerliğini gösterdi \n",
    "ve projenin gelecekteki gelişmeleri için sağlam bir temel oluşturdu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
